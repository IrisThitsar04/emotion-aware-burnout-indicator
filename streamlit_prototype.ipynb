{"cells":[{"cell_type":"markdown","source":["**The core notebooks for this project are:**\n","\n","*   01_eda_data_cleaning.ipynb\n","*   02_baseline_models.ipynb\n","*   03_transformers.ipynb\n","*  streamlit_prototype.ipynb"],"metadata":{"id":"KW6O5WmMOGEa"}},{"cell_type":"markdown","source":["**Prototype Notebook**\n","\n","This notebook generates the prototype inference components. It produces an inference pipeline for model loading, emotion probability estimation, affective quadrant aggregation, and rule-based burnout indicator mapping, along with a lightweight Streamlit interface for presenting results in a non-diagnostic, explanatory format."],"metadata":{"id":"kRA_ctrqM4_7"}},{"cell_type":"code","source":["#project paths:\n","#project root: /content/drive/MyDrive/applied_research_project/\n","#cleaned data directory: /content/drive/MyDrive/applied_research_project/data\n","#prototype directory: /content/drive/MyDrive/applied_research_project/burnout_indicator_detection_prototype\n","#best model storage path: /content/drive/MyDrive/applied_research_project/burnout_indicator_detection_prototype/best_emo_model"],"metadata":{"id":"_-2ztF97usoc","executionInfo":{"status":"ok","timestamp":1767652153670,"user_tz":0,"elapsed":6,"user":{"displayName":"Iris May Thiri Thitsar","userId":"04920271487134687284"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2B0ZEBJdZ-5d","executionInfo":{"status":"ok","timestamp":1767652180165,"user_tz":0,"elapsed":26487,"user":{"displayName":"Iris May Thiri Thitsar","userId":"04920271487134687284"}},"outputId":"097fe92e-cac3-49c1-9e65-f82725298235"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#set working directory to the burnout indicator prototype\n","\n","%cd /content/drive/MyDrive/applied_research_project/burnout_indicator_detection_prototype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhgDsYuRb-ee","executionInfo":{"status":"ok","timestamp":1767652182382,"user_tz":0,"elapsed":2221,"user":{"displayName":"Iris May Thiri Thitsar","userId":"04920271487134687284"}},"outputId":"3d2ab277-6317-46df-a280-5a145a1f448c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/applied_research_project/burnout_indicator_detection_prototype\n"]}]},{"cell_type":"markdown","source":["#1.Transformer Inference and Burnout Indicator Pipeline  \n"],"metadata":{"id":"SZqXIBuTJkhm"}},{"cell_type":"markdown","source":["This section defines the inference pipeline used by the prototype, including model loading, emotion probability estimation, affective quadrant aggregation, and literature-informed, rule-based burnout indicator mapping."],"metadata":{"id":"dfENWuqRQ1mT"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8f945ca","outputId":"e3935079-8506-4d30-972b-0e5691b85e2b","executionInfo":{"status":"ok","timestamp":1767652183588,"user_tz":0,"elapsed":1205,"user":{"displayName":"Iris May Thiri Thitsar","userId":"04920271487134687284"}}},"source":["%%writefile inference.py\n","\n","import json\n","import torch\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import os\n","import sys\n","\n","#directory containing the fine-tuned model, tokenizer, and metadata\n","model_dir='best_emo_model'\n","\n","device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","#load tokenizer and fine-tuned transformer model\n","tokenizer=AutoTokenizer.from_pretrained(model_dir)\n","model_final=AutoModelForSequenceClassification.from_pretrained(model_dir)\n","model_final.to(device)\n","\n","#set model for inference\n","model_final.eval()\n","\n","#load saved metadata for inference and interpretation\n","with open(os.path.join(model_dir, \"meta_data.json\"), \"r\") as f:\n","  meta_data=json.load(f)\n","\n","emotion_labels=meta_data[\"emotion_labels\"]\n","emo_thresholds=np.array(meta_data[\"emo_thresholds\"])\n","categories=meta_data[\"categories\"]\n","emo_to_cat=meta_data[\"emo_to_cat\"]\n","cat_thresholds=np.array(meta_data[\"cat_thresholds\"])\n","max_len=meta_data[\"max_len\"]\n","aggregation=meta_data[\"aggregation\"]\n","\n","#sigmoid for multi-label probabilities\n","sigmoid=torch.nn.Sigmoid()\n","\n","#ensure inputs are handled as a list of strings\n","def normalise_texts(texts):\n","  if isinstance(texts, str):\n","    return [texts]\n","  return [str(t) for t in texts]\n","\n","@torch.no_grad()\n","\n","#return proabability scores for each emotion label\n","def predict_emotions_prob(text):\n","\n","  texts=normalise_texts(text)\n","\n","  enc=tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len).to(device)\n","\n","  logits=model_final(**enc).logits\n","  probs=sigmoid(logits)\n","  return probs.cpu().numpy()\n","\n","@torch.no_grad()\n","\n","#return emotion probabilities and binary predictions\n","def get_emotion_predictions(text):\n","\n","  probs=predict_emotions_prob(text)\n","  preds=(probs>=emo_thresholds).astype(int)\n","\n","  all_results=[]\n","  for row_probs, row_preds in zip(probs, preds):\n","    res=[]\n","    for label_name, p, y in zip(emotion_labels, row_probs, row_preds):\n","      res.append({\n","          \"label\": label_name,\n","          \"p\": float(p),\n","          \"y\": int(y)\n","      })\n","    all_results.append(res)\n","  return all_results\n","\n","#aggregate emotion probabilities into quadrant probabilities\n","def probs_emo_to_cat(probs_emo, emo_to_cat, categories, mode=\"noisy_or\"):\n","  probs_emo=np.asarray(probs_emo)\n","  n=probs_emo.shape[0]\n","  c=len(categories)\n","  out=np.zeros((n,c), dtype=np.float32)\n","\n","  cat_to_emoIds={cat: [i for i, c in enumerate(emo_to_cat) if c==cat] for cat in categories}\n","\n","  for j, cat in enumerate(categories):\n","    idxs=cat_to_emoIds[cat]\n","\n","    if len(idxs)==0:\n","      out[:,j]=0.0\n","    elif len(idxs)==1:\n","      out[:,j]=probs_emo[:,idxs[0]]\n","    else:\n","      out[:,j]=1.0-np.prod(1.0-probs_emo[:, idxs], axis=1)\n","  return out\n","\n","#map quadrant predictions to burnout indicator\n","def burnout_indicator_from_quadrants(pred_row):\n","\n","  col_idx={c:i for i, c in enumerate(categories)}\n","\n","  NEU=int((pred_row[col_idx[\"neutral_ambiguous\"]]))\n","  PA=int((pred_row[col_idx[\"pleasant_active\"]]))\n","  PD=int((pred_row[col_idx[\"pleasant_deactive\"]]))\n","  NA=int((pred_row[col_idx[\"unpleasant_active\"]]))\n","  ND=int((pred_row[col_idx[\"unpleasant_deactive\"]]))\n","\n","  if ND:\n","    return \"Signs of Advanced Burnout (Exhaustion/Ineffectiveness)\"\n","  elif NA:\n","    return \"Signs of Moderate Burnout (Stress/Cynicism)\"\n","  elif PA:\n","    return (\"Indicators of Engagement (No Apparent Signs of Burnout)\")\n","  elif PD:\n","    return (\"Indicators of Satisfaction (No Apparent Signs of Burnout)\")\n","  elif NEU:\n","    return (\"Ambiguous Burnout Indicator\")\n","  else:\n","    return (\"Ambiguous Burnout Indicator\")\n","\n","#full inference pipeline from text to burnout indicator\n","@torch.no_grad()\n","def predict_full(texts):\n","  probs_emo=predict_emotions_prob(texts)\n","  all_emotions=get_emotion_predictions(texts)\n","  probs_cat_all=probs_emo_to_cat(\n","      probs_emo, emo_to_cat, categories, aggregation\n","  )\n","  out=[]\n","\n","  for row_probs_cat, emo_res in zip(probs_cat_all, all_emotions):\n","      preds_cat=(row_probs_cat>=cat_thresholds).astype(int)\n","      burnout_label=burnout_indicator_from_quadrants(preds_cat)\n","      out.append(\n","          {\n","              \"emotions\": emo_res,\n","              \"quadrant_probs\":{\n","                  cat: float(p) for cat, p in zip(categories, row_probs_cat)},\n","              \"quadrant_preds\":{\n","                  cat: int(y) for cat, y in zip(categories, preds_cat)},\n","              \"burnout_indicator\": burnout_label,\n","          },\n","      )\n","  return out"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting inference.py\n"]}]},{"cell_type":"markdown","source":["#2.Prototype Application Interface (Streamlit)\n"],"metadata":{"id":"7-Et-dznJr3q"}},{"cell_type":"markdown","source":["This section implements a lightweight Streamlit-based interface that integrates the inference pipeline and presents results to the user in a non-diagnostic, explanatory format."],"metadata":{"id":"cDuZi2pGRp7b"}},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from inference import predict_full\n","\n","#configure streamlit page\n","st.set_page_config(\n","    page_title=\"Burnout Indicator Detection Prototype\",\n","    layout=\"wide\",\n",")\n","\n","st.title(\"Burnout Indicator Detection Prototype\")\n","\n","st.write(\n","    \"This prototype applies a fine-tuned transformer model to user-provided text,\"\n","    \"identifies underlying emotions, aggregates them into affective quadrants, \"\n","    \"and generates a non-diagnostic burnout indicator. It is a conceptual, literature-based \"\n","    \"research demonstration intended solely as a supportive tool to illustrate how such \"\n","    \"a model can be integrated into a web interface. It is not designed or validated \"\n","    \"for clinical or psychological diagnosis.\"\n",")\n","\n","#user input text box\n","text=st.text_area(\"Input text\", height=200, placeholder=\"Type or paste a diary text or reflective message here...\")\n","\n","#run analysis when the user clicks the button\n","if st.button(\"Analyse\") and text.strip():\n","  with st.spinner(\"Running the model...\"):\n","    results=predict_full(text)\n","  res=results[0]\n","\n","  #burnout indicator\n","  st.subheader(\"Burnout Indicator Output\")\n","  st.success(res[\"burnout_indicator\"])\n","\n","  #quadrant probabilities\n","  st.subheader(\"Affective Quadrant Profile\")\n","  qp=res[\"quadrant_probs\"]\n","\n","  st.write({\n","      \"neutral_ambiguous\": round(qp.get(\"neutral_ambiguous\", 0.0),3),\n","      \"pleasant_active\": round(qp.get(\"pleasant_active\", 0.0),3),\n","      \"pleasant_deactive\": round(qp.get(\"pleasant_deactive\", 0.0),3),\n","      \"unpleasant_active\": round(qp.get(\"unpleasant_active\", 0.0),3),\n","      \"unpleasant_deactive\": round(qp.get(\"unpleasant_deactive\", 0.0),3),\n","  })\n","\n","  #top 3 detected emotions\n","  st.subheader(\"Top 3 Detected Emotions\")\n","\n","  #sort all predicted emotions by probability\n","  emotions_sorted=sorted(res[\"emotions\"], key=lambda x: x[\"p\"], reverse=True)\n","\n","  #keep only the three highest-confidence emtions\n","  emotions=emotions_sorted[:3]\n","\n","  if emotions:\n","    table_rows=[\n","        {\n","            \"Emotion\":e[\"label\"],\n","            \"Predicted Probability\":round(e[\"p\"],3),\n","        }\n","        for e in emotions\n","    ]\n","    st.table(table_rows)\n","  else:\n","    st.info(\"No emotions detected\")\n","else:\n","  st.info(\"Enter text and click 'Analyse' to see the results.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-S_fUmVOyhP","executionInfo":{"status":"ok","timestamp":1767652184407,"user_tz":0,"elapsed":817,"user":{"displayName":"Iris May Thiri Thitsar","userId":"04920271487134687284"}},"outputId":"e05e4b09-7348-40b9-ded7-424176f4d89e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}